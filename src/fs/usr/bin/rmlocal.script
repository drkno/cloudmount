#!/bin/bash
###############################################################################
# CONFIGURATION
###############################################################################
# shellcheck source=config

. "/usr/bin/config"
##############################################################################

oldSize=0
movedSize=0

rm_time () {
	# Generate filelist and iterate through it...
	find "${local_decrypt_dir}" -type f -mtime +$REMOVE_LOCAL_FILES_AFTER_DAYS |
		while read -r n; do

			# Find the pathname relative to the root of your remote and store filename
			filename="$(echo "$n" | sed -e s@"${local_decrypt_dir}"@@)"
			destpath="$(dirname "$n" | sed -e s@"${local_decrypt_dir}"@@)"

			# Skip hidden or partial files.
			case "$n" in
				(*.partial~) continue ;;
				(*_HIDDEN~) continue ;;
				(*.QTFS) continue ;;
				(*.unionfs-fuse*) continue ;;
				(*.DS_STORE) continue ;;
			esac

			# If file is opened by another process, wait until it isn't.
			while [ "$(lsof "$n" >/dev/null 2>&1)" ] || \
				[ "$(lsof "${local_decrypt_dir}/${n}" >/dev/null 2>&1)" ] || \
				[ "$(lsof "${local_media_dir}/${n}" >/dev/null 2>&1)" ]; do
				echo "[ $(date $(printenv DATE_FORMAT)) ] File -> ${n} in use. Retrying in 10 seconds."
				sleep 10
			done

			fileSize=$(du -sb "$n" | awk '{print $1}')

			# Move file to remote destination[s], retaining path
			rclone move $rclone_options "$@" "$n" "${rclone_cloud_endpoint}${destpath}" >/dev/null 2>&1
			
                        movedSize=$((movedSize + fileSize))

                        sizeInMb=$((movedSize / 1000 / 1000))
                        diffSize=$((movedSize - oldSize))
                        if [[ "${sizeInMb}" -gt 1000 ]]; then
                                if [[ "${diffSize}" -gt "1000000000" ]]; then # greater than 1 GB
                                        oldSize=$movedSize
                                        echo "[ $(date $(printenv DATE_FORMAT)) ] $((sizeInMb / 1000)) GB uploaded"
                                fi
                        elif [[ "${diffSize}" -gt "100000000" ]]; then # greater than 100 MB
                                oldSize=$movedSize
                                echo "[ $(date $(printenv DATE_FORMAT)) ] ${sizeInMb} MB uploaded"
                        fi
		done

	find "${local_decrypt_dir}" -mindepth 1 -type d -empty -delete
}

rm_instant () {
	# Generate filelist and iterate through it...
	find "${local_decrypt_dir}" -type f |
		while read -r n; do

			# Find the pathname relative to the root of your remote and store filename
			filename="$(echo "$n" | sed -e s@"${local_decrypt_dir}"@@)"
			destpath="$(dirname "$n" | sed -e s@"${local_decrypt_dir}"@@)"

			# Skip hidden or partial files.
			case "$n" in
				(*.partial~) continue ;;
				(*_HIDDEN~) continue ;;
				(*.QTFS) continue ;;
				(*.unionfs-fuse*) continue ;;
				(*.DS_STORE) continue ;;
			esac

			# If file is opened by another process, wait until it isn't.
			while [ "$(lsof "$n" >/dev/null 2>&1)" ] || \
				[ "$(lsof "${local_decrypt_dir}/${n}" >/dev/null 2>&1)" ] || \
				[ "$(lsof "${local_media_dir}/${n}" >/dev/null 2>&1)" ]; do
				echo "[ $(date $(printenv DATE_FORMAT)) ] File -> ${n} in use. Retrying in 10 seconds."
				sleep 10
			done

			fileSize=$(du -sb "$n" | awk '{print $1}')

			# Move file to remote destination[s], retaining path
			rclone move $rclone_options "$@" "$n" "${rclone_cloud_endpoint}${destpath}" >/dev/null 2>&1
			
                        movedSize=$((movedSize + fileSize))

                        sizeInMb=$((movedSize / 1000 / 1000))
                        diffSize=$((movedSize - oldSize))
                        if [[ "${sizeInMb}" -gt 1000 ]]; then
                                if [[ "${diffSize}" -gt "1000000000" ]]; then # greater than 1 GB
                                        oldSize=$movedSize
                                        echo "[ $(date $(printenv DATE_FORMAT)) ] $((sizeInMb / 1000)) GB uploaded"
                                fi
                        elif [[ "${diffSize}" -gt "100000000" ]]; then # greater than 100 MB
                                oldSize=$movedSize
                                echo "[ $(date $(printenv DATE_FORMAT)) ] ${sizeInMb} MB uploaded"
                        fi
		done

	find "${local_decrypt_dir}" -mindepth 1 -type d -empty -delete
}

rm_space () {
	maxSize=$(($REMOVE_LOCAL_FILES_WHEN_SPACE_EXCEEDS_GB * 1000 * 1000 * 1000))
	currentSize="$(du -sb "$local_decrypt_dir" | awk '{print $1}')"
	if [ "$maxSize" -gt "$currentSize" ]; then
			echo "Current size of $(($currentSize / 1000 / 1000 / 1000)) GB has not exceeded $REMOVE_LOCAL_FILES_WHEN_SPACE_EXCEEDS_GB GB"
			exit 02
	fi

	freeup=$(($FREEUP_ATLEAST_GB * 1000 * 1000 * 1000))

	find "${local_decrypt_dir}" -type f -print0 | xargs -0 stat --format '%Y :%y %n' | sort -n | cut -d: -f2- | awk '{$1=$2=$3=""; print $0}' |
		while read -r n; do
			if [ "$movedSize" -gt "$freeup" ]; then
					spaceInGb=$(($movedSize / 1000 / 1000 / 1000))
					spaceLeft=$(($(du -sb "$local_decrypt_dir" | awk '{print $1}') / 1000 / 1000 / 1000))
					echo "[ $(date $(printenv DATE_FORMAT)) ] Removed ${spaceInGb} GB. Media in total ${spaceLeft} GB."
					break
			fi

			# Find the pathname relative to the rsoot of your remote and store filename
			filename="$(echo "$n" | sed -e s@"${local_decrypt_dir}"@@)"
			destpath="$(dirname "$n" | sed -e s@"${local_decrypt_dir}"@@)"

			# Skip hidden or partial files.
			case "$n" in
					(*.partial~) continue ;;
					(*_HIDDEN~) continue ;;
					(*.QTFS) continue ;;
					(*.fuse*) continue ;;
					(.DS_STORE) continue ;;
			esac

			# If file is opened by another process, wait until it isn't.
			while [ "$(lsof "$n" >/dev/null 2>&1)" ] || \
					[ "$(lsof "${local_decrypt_dir}/${n}" >/dev/null 2>&1)" ] || \
					[ "$(lsof "${local_media_dir}/${n}" >/dev/null 2>&1)" ]; do
					echo "[ $(date $(printenv DATE_FORMAT)) ] File -> ${n} in use. Retrying in 10 seconds."
					sleep 10
			done

			fileSize=$(du -sb "$n" | awk '{print $1}')
			
			# Move file to remote destination[s], retaining path
			rclone move $rclone_options "$@" "$n" "${rclone_cloud_endpoint}${destpath}" >/dev/null 2>&1
			
                        movedSize=$((movedSize + fileSize))

                        sizeInMb=$((movedSize / 1000 / 1000))
                        diffSize=$((movedSize - oldSize))
                        if [[ "${sizeInMb}" -gt 1000 ]]; then
                                if [[ "${diffSize}" -gt "1000000000" ]]; then # greater than 1 GB
                                        oldSize=$movedSize
                                        echo "[ $(date $(printenv DATE_FORMAT)) ] $((sizeInMb / 1000)) GB uploaded"
                                fi
                        elif [[ "${diffSize}" -gt "100000000" ]]; then # greater than 100 MB
                                oldSize=$movedSize
                                echo "[ $(date $(printenv DATE_FORMAT)) ] ${sizeInMb} MB uploaded"
                        fi
		done

	find "${local_decrypt_dir}" -mindepth 1 -type d -empty -delete
}

# If script is already running; abort.
if pidof -o %PPID -x "$(basename "$0")"; then
	echo "[ $(date $(printenv DATE_FORMAT)) ] Upload already in progress. Aborting."
	exit 3
fi

check_rclone_cloud

echo "Removing files based on ${REMOVE_LOCAL_FILES_BASED_ON}"

if [ "$REMOVE_LOCAL_FILES_BASED_ON" = "space" ]; then
	rm_space
elif [ "$REMOVE_LOCAL_FILES_BASED_ON" = "time" ]; then
	rm_time
elif [ "$REMOVE_LOCAL_FILES_BASED_ON" = "instant" ]; then
	rm_instant
else
	echo "[ $(date $(printenv DATE_FORMAT)) ] no option to remove old files"
	exit 02
fi
